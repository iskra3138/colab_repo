{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XAI_Visualization Methods_TF1.x_Share",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "cGDBBMvdqiEl",
        "75uaCXrYqiFH",
        "rymHjWwnqiFz"
      ],
      "authorship_tag": "ABX9TyOnWEnsKMr/JYdpjmjQg5W8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskra3138/colab_repo/blob/master/XAI_Visualization_Methods_TF1_x_Share.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pfk-sNJrqiDT",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMP_PQR51aTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://iskra3138_mvtec/my_mvtec_tpumodel.h5 ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i5yk0d_YJ2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "AHfADBs8QegC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from PIL import Image as pil_image\n",
        "import cv2\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import model_from_json\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "O1Dq5iO2Qegk",
        "colab_type": "text"
      },
      "source": [
        "## CAM vs. Grad-CAM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FwM_8xznQehK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('my_mvtec_tpumodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4nArxoT3rqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "IMAGE_SIZE =  [224, 224]\n",
        "\n",
        "validation_fns = 'gs://iskra3138_mvtec_tfrecords/valid.tfrecords'\n",
        "\n",
        "def parse_tfrecord(example):\n",
        "    features = {\n",
        "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    # decode the TFRecord\n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "    \n",
        "    label = example['label']\n",
        "    #label = tf.one_hot(indices=label, depth=2)\n",
        "    image = tf.io.decode_jpeg(example['image_raw'], channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0\n",
        "    image = tf.image.resize(image, IMAGE_SIZE)\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "#validation_dataset = load_dataset(validation_fns).shuffle(1000).batch(1000).prefetch(AUTO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA56MfCjVNx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NG_filter_fn(img, label):\n",
        "  return tf.math.equal(label, 0)\n",
        "def OK_filter_fn(img, label):\n",
        "  return tf.math.equal(label, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVaUXP3F5VhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_class_sapling (fns, class_idx, batch_size) :\n",
        "  if class_idx == 0 :\n",
        "    NG_dataset = load_dataset(fns).filter(NG_filter_fn).shuffle(1000).batch(batch_size).prefetch(AUTO).repeat()\n",
        "    NG_iter = NG_dataset.make_one_shot_iterator()\n",
        "    return NG_iter\n",
        "  else :\n",
        "    OK_dataset = load_dataset(fns).filter(OK_filter_fn).shuffle(1000).batch(batch_size).prefetch(AUTO).repeat()\n",
        "    OK_iter = OK_dataset.make_one_shot_iterator()\n",
        "    return OK_iter\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0f81-iuYiXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iter = make_class_sapling(validation_fns, 1, 9)\n",
        "i, l = iter.get_next()\n",
        "with tf.Session() as sess:\n",
        "  print (sess.run(l))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuTa-YYLUjlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h_j1kakUjiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmVh2J5VUjel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJYvgvaXUjcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deIk_907UjZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3S9AQABUjWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IDQLTXAZQehU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "img_paths=[]\n",
        "for i in range(5):\n",
        "  img_paths.append(random.choice(glob.glob('/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/*.jpg')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3lFf78Qkpk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCGP-liAxNAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_paths = ['/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/cut_011_3_13.jpg',\n",
        " '/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/cut_007_14_5.jpg',\n",
        " '/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/cut_015_1_2.jpg',\n",
        " '/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/cut_014_6_5.jpg',\n",
        " '/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/cut_007_13_0.jpg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRkvp4frksKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/cut_010_3_5.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "BYUK6n8pQehh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''def preprocess_input(img_path):\n",
        "    img = pil_image.open(img_path).resize((224, 224))\n",
        "    img_arr = np.asarray(img)[:, :, :3] / 255.\n",
        "    img_tensor = np.expand_dims(img_arr, 0)\n",
        "    \n",
        "    return img_arr, img_tensor'''\n",
        "  \n",
        "def preprocess_input(img_path):  \n",
        "  img_string = tf.io.read_file(img_path)\n",
        "  img = tf.image.decode_jpeg(img_string)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img_arr = tf.image.resize(img, (224, 224))\n",
        "  with tf.compat.v1.Session() as sess:\n",
        "    img_arr = sess.run(img_arr)\n",
        "  img_arr /= 255.0\n",
        "  img_tensor = np.expand_dims(img_arr, axis=0)  \n",
        "  return img_arr, img_tensor\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "F7BasX4KQehr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_cam(model, img_path, class_idx):\n",
        "    \n",
        "    ## img_path -> preprocessed image tensor\n",
        "    img_arr, img_tensor = preprocess_input(img_path)\n",
        "    \n",
        "    ## preprocessed image tensor -> last_conv_output, predictions\n",
        "    get_output = K.function([model.layers[0].input], [model.get_layer('conv5_block3_out').output, model.layers[-1].output])\n",
        "    [conv_outputs, predictions] = get_output([img_tensor])\n",
        "    \n",
        "    conv_outputs = conv_outputs[0, :, :, :]\n",
        "    class_weights = model.layers[-1].get_weights()[0]\n",
        "    \n",
        "    ## generate cam\n",
        "    cam = np.zeros(dtype=np.float32, shape=conv_outputs.shape[0:2])\n",
        "    for i, w in enumerate(class_weights[:, class_idx]):\n",
        "        cam += w * conv_outputs[:, :, i]\n",
        "        \n",
        "    cam /= np.max(cam)\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    \n",
        "    return img_arr, cam, predictions    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "-c87D4cvQeh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "S_IgrdAAQeiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_grad_cam(model, img_path, class_idx):\n",
        "\n",
        "    ## img_path -> preprocessed image tensor\n",
        "    img_arr, img_tensor = preprocess_input(img_path)\n",
        "\n",
        "    ## get the derivative of y^c w.r.t A^k\n",
        "    y_c = model.layers[-1].output.op.inputs[0][0, class_idx]\n",
        "#     y_c = model.output[0, class_idx]\n",
        "    \n",
        "    layer_output = model.get_layer('conv5_block3_out').output\n",
        "    #layer_output = model.layers[-4].output\n",
        "    \n",
        "    grads = K.gradients(y_c, layer_output)[0]\n",
        "    gradient_fn = K.function([model.input], [layer_output, grads, model.layers[-1].output])\n",
        "    \n",
        "    conv_output, grad_val, predictions = gradient_fn([img_tensor])\n",
        "    conv_output, grad_val = conv_output[0], grad_val[0]\n",
        "    \n",
        "    weights = np.mean(grad_val, axis=(0, 1))\n",
        "    cam = np.dot(conv_output, weights)\n",
        "    \n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    \n",
        "    ## Relu\n",
        "    cam = np.maximum(cam, 0)\n",
        "    \n",
        "    cam = cam / cam.max()\n",
        "    \n",
        "    return img_arr, cam, predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "by6JEAlzQeiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_bbox(img, cam, threshold):\n",
        "    labeled, nr_objects = ndimage.label(cam > threshold)\n",
        "    props = regionprops(labeled)\n",
        "    return props"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "iLuhcx7GQei0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_guided_model():\n",
        "    \n",
        "    if 'GuidedBackProp' not in ops._gradient_registry._registry:\n",
        "        @ops.RegisterGradient('GuidedBackProp')\n",
        "        def _GruidedBackProp(op, grad):\n",
        "            dtype = op.inputs[0].dtype\n",
        "            return grad * tf.cast(grad > 0., dtype) * tf.cast(op.inputs[0] > 0., dtype)\n",
        "        \n",
        "    g = tf.get_default_graph()\n",
        "    with g.gradient_override_map({'Relu': 'GuidedBackProp'}):\n",
        "        \n",
        "        \n",
        "        new_model = tf.keras.models.load_model('my_mvtec_tpumodel.h5')\n",
        "        \n",
        "        return new_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5U9yaUWVQei_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "guided_model = build_guided_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS0PDzuvCQxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img1, img2 = preprocess_input(img_paths[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJVejNpWCRlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3BQjKpICTc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "guided_model.predict(img2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "H1btatGoQejM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def guided_backprop(model, img, activation_layer):\n",
        "    input_img = model.input\n",
        "    #layer_output = model.layers[activation_layer_idx].output\n",
        "    layer_output = model.get_layer('conv5_block3_out').output\n",
        "    grads = K.gradients(layer_output, input_img)[0]\n",
        "    gradient_fn = K.function([input_img], [grads])\n",
        "    grads_val = gradient_fn([img])[0]\n",
        "    return grads_val\n",
        "\n",
        "def deprocess_image(x):\n",
        "    x = x.copy()\n",
        "    if np.ndim(x) > 3:\n",
        "        x = np.squeeze(x)\n",
        "    \n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "    \n",
        "    # clip\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "    \n",
        "    ## RGB array\n",
        "    x *= 255.\n",
        "    \n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eq7sa8DcQejY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_guided_grad_cam(guided_model, img_path, grad_cam):\n",
        "    gb = guided_backprop(guided_model, img=preprocess_input(img_path)[1], activation_layer='conv5_block3_out')\n",
        "    guided_grad_cam = gb * grad_cam[..., np.newaxis]\n",
        "    \n",
        "    return deprocess_image(guided_grad_cam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8PDJtTcVUbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################\n",
        "\n",
        "## img_path -> preprocessed image tensor\n",
        "img_arr, img_tensor = preprocess_input(path)\n",
        "\n",
        "## get the derivative of y^c w.r.t A^k\n",
        "y_c = model.layers[-1].output.op.inputs[0][0, 0]\n",
        "#     y_c = model.output[0, class_idx]\n",
        "\n",
        "layer_output = model.get_layer('conv5_block3_out').output\n",
        "#layer_output = model.layers[-4].output\n",
        "\n",
        "grads = K.gradients(y_c, layer_output)[0]\n",
        "#grads = tf.gradients(y_c, layer_output)[0]\n",
        "gradient_fn = K.function([model.input], [layer_output, grads, model.layers[-1].output])\n",
        "\n",
        "conv_output, grad_val, predictions = gradient_fn([img_tensor])\n",
        "conv_output, grad_val = conv_output[0], grad_val[0]\n",
        "\n",
        "weights = np.mean(grad_val, axis=(0, 1))\n",
        "cam = np.dot(conv_output, weights)\n",
        "\n",
        "#cam = cv2.resize(cam, (224, 224))\n",
        "\n",
        "## Relu\n",
        "cam = np.maximum(cam, 0)\n",
        "\n",
        "#cam = cam / cam.max()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4RE1lv4ZF2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grad_val[:,:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XvCA0MeZBBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgO74VFTXpO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpvOwbblk-Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######\n",
        "img, grad_cam, predictions = generate_grad_cam(model, path, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoUtMhXHk9-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################\n",
        "grad_cam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW9kQoxdk94b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-9SCv-ip4JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################\n",
        "img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "j5vnk2clQejj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(5, 6, figsize=(20, 15))\n",
        "\n",
        "for i, s in enumerate(img_paths):\n",
        "    img, cam, grad_cam, guided_grad_cam = None, None, None, None\n",
        "    \n",
        "    img_path = s\n",
        "    class_idx = 0\n",
        "    \n",
        "    _, cam, _ = generate_cam(model, img_path, class_idx)\n",
        "    img, grad_cam, predictions = generate_grad_cam(model, img_path, class_idx)\n",
        "    guided_grad_cam = generate_guided_grad_cam(guided_model, img_path, grad_cam)\n",
        "    img =img*255\n",
        "    \n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 1].imshow(cam, cmap='jet')\n",
        "    axes[i, 2].imshow(grad_cam, cmap='jet')\n",
        "    axes[i, 3].imshow(img)\n",
        "    axes[i, 3].imshow(cam, cmap='jet', alpha=0.5)\n",
        "    axes[i, 4].imshow(img)\n",
        "    axes[i, 4].imshow(grad_cam, cmap='jet', alpha=0.5)\n",
        "    axes[i, 5].imshow(guided_grad_cam)\n",
        "    \n",
        "    \n",
        "    axes[i, 0].axis('off')\n",
        "    axes[i, 1].axis('off')\n",
        "    axes[i, 2].axis('off')\n",
        "    axes[i, 3].axis('off')\n",
        "    axes[i, 4].axis('off')\n",
        "    axes[i, 5].axis('off')\n",
        "    \n",
        "    axes[0, 0].set_title(\"image\", fontsize=18)\n",
        "    axes[0, 1].set_title(\"CAM\", fontsize=18)\n",
        "    axes[0, 2].set_title(\"Grad-CAM\", fontsize=18)\n",
        "    axes[0, 3].set_title(\"CAM\", fontsize=18)\n",
        "    axes[0, 4].set_title(\"Grad-CAM\", fontsize=18)\n",
        "    axes[0, 5].set_title(\"Guided-Grad-CAM\", fontsize=18)\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uwQ5UCsOqiDZ"
      },
      "source": [
        "# CAM Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwdZ0yGQqiDa",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKLAAJpXw0co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = 'my_mvtec_tpumodel.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZysxS8apq4nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d93S-HEorQm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mr9R8WxjqiDb"
      },
      "source": [
        "### import matplotlib, numpy, cv2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1GtRSfDEqiDc",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "\n",
        "from tensorflow.python.framework import ops\n",
        "from PIL import  Image\n",
        "\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_hH3OCbfqiDe"
      },
      "source": [
        "### import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "eJlzMBofqiDh",
        "colab": {}
      },
      "source": [
        "#@title import Util code [Run Me!!!]\n",
        "\n",
        "def load_image(path, target_size):\n",
        "    img_string = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img_string)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, target_size)\n",
        "    img /= 255.0\n",
        "    img = tf.expand_dims(img, axis=0)  \n",
        "    return img\n",
        "  \n",
        "def deprocess_image(x):\n",
        "    '''\n",
        "    Same normalization as in:\n",
        "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
        "    '''\n",
        "    x = x.copy()\n",
        "    if np.ndim(x) > 3:\n",
        "        x = np.squeeze(x)\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YcFOPWGgzg3J"
      },
      "source": [
        "# CAM Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "code",
        "id": "5jrmPaqdqiDf",
        "colab": {}
      },
      "source": [
        "#@title import Grad-CAM Code [Run Me!!]\n",
        "class GradCAM:\n",
        "  def __init__(self, model, activation_layer):\n",
        "    self.model = model\n",
        "    self.activation_layer = activation_layer\n",
        "    self.tensor_function = self._get_gradcam_tensor_function()\n",
        "\n",
        "  # get partial tensor graph of CNN model\n",
        "  def _get_gradcam_tensor_function(self):\n",
        "    model_input = self.model.input\n",
        "    #y_c = self.model.outputs[0].op.inputs[0][0, self.class_idx]\n",
        "    #y_c = self.model.outputs[0].op.inputs[0]\n",
        "    y_c = self.model.output\n",
        "    A_k = self.model.get_layer(self.activation_layer).output\n",
        "    \n",
        "    tensor_function = tf.keras.models.Model([model_input], [A_k, y_c])\n",
        "    return tensor_function\n",
        "\n",
        "  # generate Grad-CAM\n",
        "  def generate(self, input_tensor, class_idx):\n",
        "    with tf.GradientTape() as tape:\n",
        "      conv_outputs, predictions = self.tensor_function(input_tensor)\n",
        "      loss = predictions[:, class_idx]\n",
        "\n",
        "    output = conv_outputs[0]\n",
        "    \n",
        "    grads = tape.gradient(loss, conv_outputs)[0]    \n",
        "    weights = np.mean(grads, axis=(0, 1))\n",
        "    \n",
        "    grad_cam = np.dot(output, weights)\n",
        "    #grad_cam = np.zeros(output.shape[0: 2], dtype = np.float32)\n",
        "    #for i, w in enumerate(weights):\n",
        "    #    grad_cam += w * output[:, :, i]\n",
        "\n",
        "    grad_cam = np.maximum(grad_cam, 0)\n",
        "    grad_cam = cv2.resize(grad_cam, (224, 224))\n",
        "    return grad_cam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p9iAyHI184y",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title import Guided Grad-CAM Code [Run Me!!]\n",
        "class Guided_GradCAM:\n",
        "  def __init__(self, model, model_file, activation_layer, method='GuidedBackProp'):\n",
        "    self.model = model\n",
        "    self.model_file = model_file\n",
        "    self.activation_layer = activation_layer\n",
        "\n",
        "    if method == 'BackProp':\n",
        "      self._register_backprop_gradient()\n",
        "      self.guided_model = self._modify_graph('BackProp')\n",
        "    elif method == 'DeconvNet':\n",
        "      self._register_deconvnet_gradient()\n",
        "      self.guided_model = self._modify_graph('DeconvNet')\n",
        "    elif method == 'GuidedBackProp':\n",
        "      self._register_guidedbackprop_gradient()\n",
        "      self.guided_model = self._modify_graph('GuidedBackProp')\n",
        "    else:\n",
        "      sys.exit('method must be (BackProp, DeconvNet, GuidedBackProp)')\n",
        "\n",
        "    self.tensor_function = self.get_tensor_function()\n",
        "\n",
        "  # register gradient\n",
        "  def _register_backprop_gradient(self):\n",
        "    if \"BackProp\" not in ops._gradient_registry._registry:\n",
        "      @ops.RegisterGradient(\"BackProp\")\n",
        "      def _BackProp(op, grad):\n",
        "        dtype = op.inputs[0].dtype\n",
        "        return grad * tf.cast(op.inputs[0] > 0., dtype)\n",
        "\n",
        "  def _register_deconvnet_gradient(self):\n",
        "    if \"DeconvNet\" not in ops._gradient_registry._registry:\n",
        "      @ops.RegisterGradient(\"DeconvNet\")\n",
        "      def _DeconvNet(op, grad):\n",
        "        dtype = op.inputs[0].dtype\n",
        "        return grad * tf.cast(grad > 0., dtype)\n",
        "\n",
        "  def _register_guidedbackprop_gradient(self):\n",
        "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
        "      @ops.RegisterGradient(\"GuidedBackProp\")\n",
        "      def _GuidedBackProp(op, grad):\n",
        "        dtype = op.inputs[0].dtype\n",
        "        return grad * tf.cast(grad > 0., dtype) * tf.cast(op.inputs[0] > 0., dtype)\n",
        "      \n",
        "  # modify model graph\n",
        "  def _modify_graph(self, name):\n",
        "    g = tf.compat.v1.get_default_graph()\n",
        "    \n",
        "    with g.gradient_override_map({'Relu': name}):\n",
        "\n",
        "      # get layers that have an activation\n",
        "      layer_dict = [layer for layer in self.model.layers[1:]\n",
        "                    if hasattr(layer, 'activation')]\n",
        "\n",
        "      # replace relu activation\n",
        "      for layer in layer_dict:\n",
        "          if layer.activation == tf.keras.activations.relu:\n",
        "              layer.activation = tf.nn.relu\n",
        "\n",
        "      # re-instanciate a new model\n",
        "      tf.keras.backend.reset_uids()\n",
        "      new_model = tf.keras.models.load_model(self.model_file)\n",
        "    return new_model\n",
        "    '''        \n",
        "    with g.gradient_override_map({'Relu': name}):       \n",
        "      new_model = tf.keras.models.load_model(self.model_file)\n",
        "      \n",
        "    return new_model\n",
        "    '''  \n",
        "  # get partial tensor graph of CNN model\n",
        "  def get_tensor_function(self):\n",
        "    method = 'max'\n",
        "    channel = 0\n",
        "    input_img = self.guided_model.input\n",
        "    layer_output = self.guided_model.get_layer(self.activation_layer).output\n",
        "    \n",
        "    if method == 'max':\n",
        "        output = tf.keras.backend.max(layer_output, axis=3)\n",
        "    elif method == 'one':\n",
        "        output = layer_output[:, :, :, channel]\n",
        "    else:\n",
        "        sys.exit('method must be (max, one)')\n",
        "       \n",
        "    tensor_function = tf.keras.models.Model([input_img], [layer_output])\n",
        "    \n",
        "    return tensor_function\n",
        "  \n",
        "  # generate saliency map(gradient)\n",
        "  def generate(self, input_tensor):\n",
        "    x = tf.convert_to_tensor(input_tensor, dtype=tf.float32)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(x)\n",
        "      layer_output = self.tensor_function(x)\n",
        "\n",
        "    grads_val = tape.gradient(layer_output, x)[0]  \n",
        "  \n",
        "    return grads_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLumCWNo63Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = [layer for layer in model.layers[1:]\n",
        "                    if hasattr(layer, 'activation')]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blJb-T6669p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0YMXoVH66b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace relu activation\n",
        "for layer in layer_dict:\n",
        "    if layer.activation == tf.keras.activations.relu :\n",
        "      print (layer.activation)\n",
        "      layer.activation = tf.nn.relu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNhxsUrG66Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.get_layer(activation_layer).output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntCFub01PKIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = [layer for layer in model.layers[1:]\n",
        "                     if hasattr(layer, 'activation')]\n",
        "        \n",
        "for layer in layer_dict:\n",
        "    if layer.activation == tf.nn.relu:\n",
        "        print(layer.activation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrmHvV3XPKO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZiDwTKkPKTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt8__HysPKLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5wt48vU1wA5",
        "colab_type": "text"
      },
      "source": [
        "### 클래스 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfWD0O0OxvAJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@ title 변경시 자동실행 { run: \"auto\" }\n",
        "method = \"GuidedBackProp\" #@param [\"BackProp\", \"DeconvNet\", \"GuidedBackProp\"]\n",
        "activation_layer = \"conv5_block3_out\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "gradcam_generator = GradCAM(model, activation_layer)\n",
        "guided_gradcam_generator = Guided_GradCAM(model, model_file, activation_layer, method=method)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VcxqLtIbqiDi"
      },
      "source": [
        "## read NGimage path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdQFEIG4qiDj",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "img_paths=[]\n",
        "for i in range(5):\n",
        "  img_paths.append(random.choice(glob.glob('/gdrive/My Drive/MVTEC_EXP/DATA/Test/NG/*.jpg')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ieUB5_dWqiDl",
        "colab": {}
      },
      "source": [
        "img_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VELrs87dqiDn"
      },
      "source": [
        "### generate Grad-CAM, Guided Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LMEKX6eYqiDn",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "\n",
        "gradcams = []\n",
        "guided_gradcams= []\n",
        "\n",
        "for img_path in img_paths:\n",
        "    img = load_image(path=img_path, target_size=(img_width, img_height))\n",
        "\n",
        "    preds = model.predict(img)\n",
        "    predicted_class = preds.argmax(axis=1)[0]\n",
        "    print (predicted_class)\n",
        "\n",
        "    gradcam = gradcam_generator.generate(img, predicted_class)\n",
        "    gradcams.append(gradcam)\n",
        "    \n",
        "    guided_gradcam = guided_gradcam_generator.generate(img)\n",
        "    guided_gradcams.append(guided_gradcam.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R18DXVt3qiDr"
      },
      "source": [
        "### Plot CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FcMlT_NuqiDr",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.7    # the right side of the subplots of the figure\n",
        "bottom = 0.2   # the bottom of the subplots of the figure\n",
        "top = 0.9      # the top of the subplots of the figure\n",
        "wspace = 0.02  # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.0   # the amount of height reserved for white space between subplots\n",
        "plt.subplots_adjust(left=left, right=right, bottom=bottom, top=top, wspace=wspace, hspace=hspace)\n",
        "\n",
        "for idx in range(len(gradcams)):\n",
        "    \n",
        "    img = cv2.imread(img_paths[idx])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "    \n",
        "    plt.subplot(3, 5, idx+1)\n",
        "    plt.imshow(img)\n",
        "    #plt.imshow(cams[idx], cmap=\"jet\", alpha=.5)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(3, 5, 5 + idx+1)\n",
        "    plt.imshow(img)\n",
        "    plt.imshow(gradcams[idx], cmap=\"jet\", alpha=.5)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    #guided_img = guided_gradcams[idx] * gradcams[idx][..., np.newaxis]\n",
        "    guided_img = guided_gradcams[idx]\n",
        "    guided_img = deprocess_image(guided_img)\n",
        "    #guided_img = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, guided_img, 1, 0) \n",
        "    guided_img = cv2.cvtColor(guided_img, cv2.COLOR_RGB2BGR)\n",
        "    \n",
        "   \n",
        "    plt.subplot(3, 5, 10 + idx+1)\n",
        "    plt.imshow(guided_img)\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KzXOTl7sqiDz"
      },
      "source": [
        "## read OK image path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "248BcavZqiDz",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "img_paths=[]\n",
        "for i in range(5):\n",
        "  img_paths.append(random.choice(glob.glob('/gdrive/My Drive/MVTEC_EXP/DATA/Test/OK/*.jpg')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dRFfiTBQqiD0",
        "colab": {}
      },
      "source": [
        "img_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bi0G7t3mqiD2"
      },
      "source": [
        "### generate cam(class activation map)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IIWckYAp1fp2",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "\n",
        "gradcams = []\n",
        "guided_gradcams= []\n",
        "\n",
        "for img_path in img_paths:\n",
        "    img = load_image(path=img_path, target_size=(img_width, img_height))\n",
        "\n",
        "    preds = model.predict(img)\n",
        "    predicted_class = preds.argmax(axis=1)[0]\n",
        "    print (predicted_class)\n",
        "\n",
        "    gradcam = gradcam_generator.generate(img, predicted_class)\n",
        "    gradcams.append(gradcam)\n",
        "    \n",
        "    guided_gradcam = guided_gradcam_generator.generate(img, gradcam)\n",
        "    guided_gradcams.append(guided_gradcam.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9C5bnFVk1fp6"
      },
      "source": [
        "### Plot CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QtLIEuP41fp6",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "left  = 0.125  # the left side of the subplots of the figure\n",
        "right = 0.7    # the right side of the subplots of the figure\n",
        "bottom = 0.2   # the bottom of the subplots of the figure\n",
        "top = 0.9      # the top of the subplots of the figure\n",
        "wspace = 0.02  # the amount of width reserved for blank space between subplots\n",
        "hspace = 0.0   # the amount of height reserved for white space between subplots\n",
        "plt.subplots_adjust(left=left, right=right, bottom=bottom, top=top, wspace=wspace, hspace=hspace)\n",
        "\n",
        "for idx in range(len(gradcams)):\n",
        "    \n",
        "    img = cv2.imread(img_paths[idx])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (img_width, img_height))\n",
        "    \n",
        "    plt.subplot(3, 5, idx+1)\n",
        "    plt.imshow(img)\n",
        "    #plt.imshow(cams[idx], cmap=\"jet\", alpha=.5)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(3, 5, 5 + idx+1)\n",
        "    plt.imshow(img)\n",
        "    plt.imshow(gradcams[idx], cmap=\"jet\", alpha=.5)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    #guided_gradcam = gradient[idx] * gradcams[idx][..., np.newaxis]\n",
        "    guided_img = deprocess_image(guided_gradcams[idx])\n",
        "    guided_img = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, guided_img, 1, 0) \n",
        "    \n",
        "   \n",
        "    plt.subplot(3, 5, 10 + idx+1)\n",
        "    plt.imshow(guided_img)\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PogXh3KlqiD_",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cGDBBMvdqiEl"
      },
      "source": [
        "# LIME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zMsyqfQUqiEl"
      },
      "source": [
        "출처: https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20Image%20Classification%20Keras.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVIxBrAaqiEm",
        "colab": {}
      },
      "source": [
        "!pip install lime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z06Si8b1qiEn",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.applications import inception_v3 as inc_net\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "print('Notebook run using keras:', keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IaCjJE_dqiEo",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7qLC3lHLqiEp",
        "colab": {}
      },
      "source": [
        "cd '/gdrive/My Drive/MVTEC_LEATHER/EXP/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WnH8cA9DqiEq"
      },
      "source": [
        "#### import model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fWC_XPDyqiEq",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model('my_mvtec_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mA0ulNuqiEs",
        "colab": {}
      },
      "source": [
        "def transform_img_fn(path_list):\n",
        "    out = []\n",
        "    for img_path in path_list:\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = x/255.0\n",
        "        out.append(x)\n",
        "    return np.vstack(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tL05Ob9SqiEt"
      },
      "source": [
        "Let's see the top 5 prediction for some image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_79r3QHdqiEt",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "img_paths=[]\n",
        "for i in range(1):\n",
        "  img_path=random.choice(glob.glob('/gdrive/My Drive/MVTEC_LEATHER/EXP/Test/NG/*.jpg'))\n",
        "  img_paths.append(img_path)\n",
        "images = transform_img_fn(img_paths)\n",
        "# I'm dividing by 2 and adding 0.5 because of how this Inception represents images\n",
        "plt.imshow(images[0] / 2 + 0.5)\n",
        "preds = model.predict(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YB1TQSRjqiEu"
      },
      "source": [
        "#### Explanation\n",
        "Now let's get an explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ARepTsvqiEv",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os,sys\n",
        "try:\n",
        "    import lime\n",
        "except:\n",
        "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
        "    import lime\n",
        "from lime import lime_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyeTnbD6qiEx",
        "colab": {}
      },
      "source": [
        "explainer = lime_image.LimeImageExplainer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9RNagEJqiEy"
      },
      "source": [
        "hide_color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels. Here, we set it to 0 (in the representation used by inception model, 0 means gray)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S5SOKOrIqiE0",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels\n",
        "explanation = explainer.explain_instance(images[0], model.predict, top_labels=2, hide_color=0, num_samples=2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSlhyfg-qiE2"
      },
      "source": [
        "Image classifiers are a bit slow. Notice that an explanation on my Surface Book dGPU took 1min 29s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rklod8giqiE2"
      },
      "source": [
        "#### Now let's see the explanation for the top class\n",
        "We can see the top 1 superpixels that are most positive towards the class with the rest of the image hidden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rc7e-qTcqiE2",
        "colab": {}
      },
      "source": [
        "from skimage.segmentation import mark_boundaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlYm4El1qiE6",
        "colab": {}
      },
      "source": [
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
        "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "13FdEw8nqiE8"
      },
      "source": [
        "Or with the rest of the image present:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LIRLqSyUqiE8",
        "colab": {}
      },
      "source": [
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=10, hide_rest=False)\n",
        "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gMnCiEPzqiE9"
      },
      "source": [
        "\n",
        "We can also see the 'pros and cons' (pros in green, cons in red)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7SRpMrSCqiE-",
        "colab": {}
      },
      "source": [
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
        "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jTvx32tKqiE_"
      },
      "source": [
        "Or the pros and cons that have weight at least 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xbK94qHSqiFA",
        "colab": {}
      },
      "source": [
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=1000, hide_rest=False, min_weight=0.1)\n",
        "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3f0saRUZqiFB"
      },
      "source": [
        "\n",
        "Let's see the explanation for the second highest prediction\n",
        "Most positive towards wombat:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mZhooCsdqiFC",
        "colab": {}
      },
      "source": [
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=True, num_features=5, hide_rest=True)\n",
        "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0XFYLAiiqiFD"
      },
      "source": [
        "Pros and cons:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BlxIfuk3qiFE",
        "colab": {}
      },
      "source": [
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=False, num_features=10, hide_rest=False)\n",
        "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQawai8JqiFG",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75uaCXrYqiFH"
      },
      "source": [
        "# SHAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gJVyKN1KqiFI"
      },
      "source": [
        "출처: https://slundberg.github.io/shap/notebooks/ImageNet%20VGG16%20Model%20with%20Keras.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7degNSIqiFI",
        "colab": {}
      },
      "source": [
        "!pip install shap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMr__DddqiFJ",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing import image\n",
        "import requests\n",
        "from skimage.segmentation import slic\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import shap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lyUMax9fqiFK",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXZ__wmQqiFN",
        "colab": {}
      },
      "source": [
        "cd '/gdrive/My Drive/MVTEC_LEATHER/EXP/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "olQnCosUqiFO"
      },
      "source": [
        "#### import model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u7rH_vwDqiFO",
        "colab": {}
      },
      "source": [
        "feature_names=['NG','OK']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ohBJDKMWqiFQ",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model('my_mvtec_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i_49A4gdqiFR"
      },
      "source": [
        "#### NG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eX2ogtxwqiFR",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "# load an image\n",
        "file = random.choice(glob.glob('/gdrive/My Drive/MVTEC_LEATHER/EXP/Test/NG/*.jpg'))\n",
        "img = image.load_img(file, target_size=(224, 224))\n",
        "img_orig = image.img_to_array(img)/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V6mofY-1qiFU",
        "colab": {}
      },
      "source": [
        "# segment the image so we don't have to explain every pixel\n",
        "segments_slic = slic(img, n_segments=30, compactness=30, sigma=3)\n",
        "#segments_slic = slic(img, n_segments=500, compactness=30, sigma=3)\n",
        "plt.imshow(segments_slic);\n",
        "plt.axis('off');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UjrRVaHGqiFV",
        "colab": {}
      },
      "source": [
        "# define a function that depends on a binary mask representing if an image region is hidden\n",
        "def mask_image(zs, segmentation, image, background=None):\n",
        "    if background is None:\n",
        "        background = image.mean((0,1))\n",
        "    out = np.zeros((zs.shape[0], image.shape[0], image.shape[1], image.shape[2]))\n",
        "    for i in range(zs.shape[0]):\n",
        "        out[i,:,:,:] = image\n",
        "        for j in range(zs.shape[1]):\n",
        "            if zs[i,j] == 0:\n",
        "                out[i][segmentation == j,:] = background\n",
        "    return out\n",
        "def f(z):\n",
        "    return model.predict((mask_image(z, segments_slic, img_orig, 255))/255.0)\n",
        "    #return model.predict(preprocess_input(mask_image(z, segments_slic, img_orig, 255)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EduU1IJSqiFZ",
        "colab": {}
      },
      "source": [
        "# use Kernel SHAP to explain the network's predictions\n",
        "explainer = shap.KernelExplainer(f, np.zeros((1,50)))\n",
        "shap_values = explainer.shap_values(np.ones((1,50)), nsamples=1000) # runs model 1000 times"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qeBKozvIqiFb",
        "colab": {}
      },
      "source": [
        "# get the top predictions from the model\n",
        "#preds = model.predict(preprocess_input(np.expand_dims(img_orig.copy(), axis=0)))\n",
        "preds = model.predict(np.expand_dims(img_orig.copy(), axis=0))\n",
        "top_preds = np.argsort(-preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w1sM821FqiFc",
        "colab": {}
      },
      "source": [
        "def fill_segmentation(values, segmentation):\n",
        "    out = np.zeros(segmentation.shape)\n",
        "    for i in range(len(values)):\n",
        "        out[segmentation == i] = values[i]\n",
        "    return out\n",
        "\n",
        "# plot our explanations\n",
        "fig, axes = pl.subplots(nrows=1, ncols=3, figsize=(12,3))\n",
        "inds = top_preds[0]\n",
        "axes[0].imshow(img)\n",
        "axes[0].axis('off')\n",
        "max_val = np.max([np.max(np.abs(shap_values[i][:,:-1])) for i in range(len(shap_values))])\n",
        "for i in range(2):\n",
        "    m = fill_segmentation(shap_values[inds[i]][0], segments_slic)\n",
        "    axes[i+1].set_title(feature_names[inds[i]])\n",
        "    axes[i+1].imshow(img.convert('LA'), alpha=0.15)\n",
        "    im = axes[i+1].imshow(m, cmap=cm, vmin=-max_val, vmax=max_val)\n",
        "    axes[i+1].axis('off')\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
        "cb.outline.set_visible(False)\n",
        "pl.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UgCjb7_BqiFj",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RQ5CTKqtqiFk"
      },
      "source": [
        "#### OK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "unxB-RidqiFl",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "# load an image\n",
        "file = random.choice(glob.glob('/gdrive/My Drive/MVTEC_LEATHER/EXP/Test/OK/*.jpg'))\n",
        "img = image.load_img(file, target_size=(224, 224))\n",
        "img_orig = image.img_to_array(img)/255.0\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RR9zBzPwqiFm",
        "colab": {}
      },
      "source": [
        "# segment the image so we don't have to explain every pixel\n",
        "segments_slic = slic(img, n_segments=30, compactness=30, sigma=3)\n",
        "#segments_slic = slic(img, n_segments=500, compactness=30, sigma=3)\n",
        "plt.imshow(segments_slic);\n",
        "plt.axis('off');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nYXiv2aSqiFn",
        "colab": {}
      },
      "source": [
        "# define a function that depends on a binary mask representing if an image region is hidden\n",
        "def mask_image(zs, segmentation, image, background=None):\n",
        "    if background is None:\n",
        "        background = image.mean((0,1))\n",
        "    out = np.zeros((zs.shape[0], image.shape[0], image.shape[1], image.shape[2]))\n",
        "    for i in range(zs.shape[0]):\n",
        "        out[i,:,:,:] = image\n",
        "        for j in range(zs.shape[1]):\n",
        "            if zs[i,j] == 0:\n",
        "                out[i][segmentation == j,:] = background\n",
        "    return out\n",
        "def f(z):\n",
        "    return model.predict(preprocess_input(mask_image(z, segments_slic, img_orig, 255)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F1HmhWh7qiFn",
        "colab": {}
      },
      "source": [
        "# use Kernel SHAP to explain the network's predictions\n",
        "explainer = shap.KernelExplainer(f, np.zeros((1,50)))\n",
        "shap_values = explainer.shap_values(np.ones((1,50)), nsamples=2000) # runs model 1000 times"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EbJ1n-dcqiFo",
        "colab": {}
      },
      "source": [
        "# get the top predictions from the model\n",
        "preds = model.predict(preprocess_input(np.expand_dims(img_orig.copy(), axis=0)))\n",
        "top_preds = np.argsort(-preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uNLTyc1TqiFp",
        "colab": {}
      },
      "source": [
        "# make a color map\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "colors = []\n",
        "for l in np.linspace(1,0,100):\n",
        "    colors.append((245/255,39/255,87/255,l))\n",
        "for l in np.linspace(0,1,100):\n",
        "    colors.append((24/255,196/255,93/255,l))\n",
        "cm = LinearSegmentedColormap.from_list(\"shap\", colors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3e-VSzcrqiFq",
        "colab": {}
      },
      "source": [
        "def fill_segmentation(values, segmentation):\n",
        "    out = np.zeros(segmentation.shape)\n",
        "    for i in range(len(values)):\n",
        "        out[segmentation == i] = values[i]\n",
        "    return out\n",
        "\n",
        "# plot our explanations\n",
        "fig, axes = pl.subplots(nrows=1, ncols=3, figsize=(12,3))\n",
        "inds = top_preds[0]\n",
        "axes[0].imshow(img)\n",
        "axes[0].axis('off')\n",
        "max_val = np.max([np.max(np.abs(shap_values[i][:,:-1])) for i in range(len(shap_values))])\n",
        "for i in range(2):\n",
        "    m = fill_segmentation(shap_values[inds[i]][0], segments_slic)\n",
        "    axes[i+1].set_title(feature_names[inds[i]])\n",
        "    axes[i+1].imshow(img.convert('LA'), alpha=0.15)\n",
        "    im = axes[i+1].imshow(m, cmap=cm, vmin=-max_val, vmax=max_val)\n",
        "    axes[i+1].axis('off')\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
        "cb.outline.set_visible(False)\n",
        "pl.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pOM4izNVqiFr",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VWURApzpqiFt"
      },
      "source": [
        "### Original Source Code\n",
        "출처: https://github.com/slundberg/shap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJ5PiZR4qiFt",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "# load an image\n",
        "file = random.choice(glob.glob('/gdrive/My Drive/MVTEC_LEATHER/EXP/Test/NG/*.jpg'))\n",
        "X = image.load_img(file, target_size=(224, 224))\n",
        "X = image.img_to_array(X)\n",
        "X = np.expand_dims(X, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e5BsRYOpqiFv",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import json\n",
        "import shap\n",
        "\n",
        "# load pre-trained model and choose two images to explain\n",
        "#model = VGG16(weights='imagenet', include_top=True)\n",
        "#X,y = shap.datasets.imagenet50()\n",
        "to_explain = X\n",
        "'''\n",
        "# load the ImageNet class names\n",
        "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "fname = shap.datasets.cache(url)\n",
        "with open(fname) as f:\n",
        "    class_names = json.load(f)\n",
        "'''\n",
        "class_names=['NG','OK']\n",
        "\n",
        "# explain how the input to the 344th layer of the model explains the top two classes\n",
        "def map2layer(x, layer):\n",
        "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
        "    return K.get_session().run(model.layers[layer].input, feed_dict)\n",
        "e = shap.GradientExplainer(\n",
        "    (model.layers[344].input, model.layers[-1].output),\n",
        "    map2layer(X, 344),\n",
        "    local_smoothing=0 # std dev of smoothing noise\n",
        ")\n",
        "shap_values,indexes = e.shap_values(map2layer(to_explain, 344), ranked_outputs=2)\n",
        "\n",
        "# get the names for the classes\n",
        "index_names = np.vectorize(lambda x: class_names[x])(indexes)\n",
        "\n",
        "# plot the explanations\n",
        "shap.image_plot(shap_values, to_explain, index_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LrVoUf1JqiFw",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import json\n",
        "import shap\n",
        "\n",
        "# load pre-trained model and choose two images to explain\n",
        "#model = VGG16(weights='imagenet', include_top=True)\n",
        "#X,y = shap.datasets.imagenet50()\n",
        "to_explain = X\n",
        "'''\n",
        "# load the ImageNet class names\n",
        "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "fname = shap.datasets.cache(url)\n",
        "with open(fname) as f:\n",
        "    class_names = json.load(f)\n",
        "'''\n",
        "class_names=['NG','OK']\n",
        "\n",
        "# explain how the input to the 80h layer of the model explains the top two classes\n",
        "def map2layer(x, layer):\n",
        "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
        "    return K.get_session().run(model.layers[layer].input, feed_dict)\n",
        "e = shap.GradientExplainer(\n",
        "    (model.layers[80].input, model.layers[-1].output),\n",
        "    map2layer(X, 80),\n",
        "    local_smoothing=0 # std dev of smoothing noise\n",
        ")\n",
        "shap_values,indexes = e.shap_values(map2layer(to_explain, 80), ranked_outputs=2)\n",
        "\n",
        "# get the names for the classes\n",
        "index_names = np.vectorize(lambda x: class_names[x])(indexes)\n",
        "\n",
        "# plot the explanations\n",
        "shap.image_plot(shap_values, to_explain, index_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D6Nc-KrJqiFx",
        "colab": {}
      },
      "source": [
        "for i, l in enumerate(model.layers):\n",
        "  print (i, l.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rymHjWwnqiFz"
      },
      "source": [
        "# IntegratedGradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OcgedaozqiF0"
      },
      "source": [
        "출처 ; https://github.com/hiranumn/IntegratedGradients/blob/master/examples/VGG%20example.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "T8xxWBYyqiF0",
        "colab": {}
      },
      "source": [
        "#@title IntegratedGradients Class import\n",
        "################################################################\n",
        "# Implemented by Naozumi Hiranuma (hiranumn@uw.edu)            #\n",
        "#                                                              #\n",
        "# Keras-compatible implmentation of Integrated Gradients       # \n",
        "# proposed in \"Axiomatic attribution for deep neuron networks\" #\n",
        "# (https://arxiv.org/abs/1703.01365).                          #\n",
        "#                                                              #\n",
        "# Keywords: Shapley values, interpretable machine learning     #\n",
        "################################################################\n",
        "\n",
        "from __future__ import division, print_function\n",
        "import numpy as np\n",
        "from time import sleep\n",
        "import sys\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "'''\n",
        "Integrated gradients approximates Shapley values by integrating partial\n",
        "gradients with respect to input features from reference input to the\n",
        "actual input. The following class implements the paper \"Axiomatic attribution\n",
        "for deep neuron networks\".\n",
        "'''\n",
        "class integrated_gradients:\n",
        "    # model: Keras model that you wish to explain.\n",
        "    # outchannels: In case the model are multi tasking, you can specify which output you want explain .\n",
        "    def __init__(self, model, outchannels=[], verbose=1):\n",
        "    \n",
        "        #get backend info (either tensorflow or theano)\n",
        "        self.backend = K.backend()\n",
        "        \n",
        "        #load model supports keras.Model and keras.Sequential\n",
        "        if isinstance(model, Sequential):\n",
        "            self.model = model.model\n",
        "        elif isinstance(model, Model):\n",
        "            self.model = model\n",
        "        else:\n",
        "            print(\"Invalid input model\")\n",
        "            return -1\n",
        "        \n",
        "        #load input tensors\n",
        "        self.input_tensors = []\n",
        "        for i in self.model.inputs:\n",
        "            self.input_tensors.append(i)\n",
        "        # The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
        "        # to be passed as input to any Keras function that uses \n",
        "        # a different behavior at train time and test time.\n",
        "        self.input_tensors.append(K.learning_phase())\n",
        "        \n",
        "        #If outputchanels are specified, use it.\n",
        "        #Otherwise evalueate all outputs.\n",
        "        self.outchannels = outchannels\n",
        "        if len(self.outchannels) == 0: \n",
        "            if verbose: print(\"Evaluated output channel (0-based index): All\")\n",
        "            if K.backend() == \"tensorflow\":\n",
        "                self.outchannels = range(self.model.output.shape[1]._value)\n",
        "            elif K.backend() == \"theano\":\n",
        "                self.outchannels = range(self.model.output._keras_shape[1])\n",
        "        else:\n",
        "            if verbose: \n",
        "                print(\"Evaluated output channels (0-based index):\")\n",
        "                print(','.join([str(i) for i in self.outchannels]))\n",
        "                \n",
        "        #Build gradient functions for desired output channels.\n",
        "        self.get_gradients = {}\n",
        "        if verbose: print(\"Building gradient functions\")\n",
        "        \n",
        "        # Evaluate over all requested channels.\n",
        "        for c in self.outchannels:\n",
        "            # Get tensor that calculates gradient\n",
        "            if K.backend() == \"tensorflow\":\n",
        "                gradients = self.model.optimizer.get_gradients(self.model.output[:, c], self.model.input)\n",
        "            if K.backend() == \"theano\":\n",
        "                gradients = self.model.optimizer.get_gradients(self.model.output[:, c].sum(), self.model.input)\n",
        "                \n",
        "            # Build computational graph that computes the tensors given inputs\n",
        "            self.get_gradients[c] = K.function(inputs=self.input_tensors, outputs=gradients)\n",
        "            \n",
        "            # This takes a lot of time for a big model with many tasks.\n",
        "            # So lets print the progress.\n",
        "            if verbose:\n",
        "                sys.stdout.write('\\r')\n",
        "                sys.stdout.write(\"Progress: \"+str(int((c+1)*1.0/len(self.outchannels)*1000)*1.0/10)+\"%\")\n",
        "                sys.stdout.flush()\n",
        "        # Done\n",
        "        if verbose: print(\"\\nDone.\")\n",
        "            \n",
        "                \n",
        "    '''\n",
        "    Input: sample to explain, channel to explain\n",
        "    Optional inputs:\n",
        "        - reference: reference values (defaulted to 0s).\n",
        "        - steps: # steps from reference values to the actual sample (defualted to 50).\n",
        "    Output: list of numpy arrays to integrated over.\n",
        "    '''\n",
        "    def explain(self, sample, outc=0, reference=False, num_steps=50, verbose=0):\n",
        "        \n",
        "        # Each element for each input stream.\n",
        "        samples = []\n",
        "        numsteps = []\n",
        "        step_sizes = []\n",
        "        \n",
        "        # If multiple inputs are present, feed them as list of np arrays. \n",
        "        if isinstance(sample, list):\n",
        "            #If reference is present, reference and sample size need to be equal.\n",
        "            if reference != False: \n",
        "                assert len(sample) == len(reference)\n",
        "            for i in range(len(sample)):\n",
        "                if reference == False:\n",
        "                    _output = integrated_gradients.linearly_interpolate(sample[i], False, num_steps)\n",
        "                else:\n",
        "                    _output = integrated_gradients.linearly_interpolate(sample[i], reference[i], num_steps)\n",
        "                samples.append(_output[0])\n",
        "                numsteps.append(_output[1])\n",
        "                step_sizes.append(_output[2])\n",
        "        \n",
        "        # Or you can feed just a single numpy arrray. \n",
        "        elif isinstance(sample, np.ndarray):\n",
        "            _output = integrated_gradients.linearly_interpolate(sample, reference, num_steps)\n",
        "            samples.append(_output[0])\n",
        "            numsteps.append(_output[1])\n",
        "            step_sizes.append(_output[2])\n",
        "            \n",
        "        # Desired channel must be in the list of outputchannels\n",
        "        assert outc in self.outchannels\n",
        "        if verbose: print(\"Explaning the \"+str(self.outchannels[outc])+\"th output.\")\n",
        "            \n",
        "        # For tensorflow backend\n",
        "        _input = []\n",
        "        for s in samples:\n",
        "            _input.append(s)\n",
        "        _input.append(0)\n",
        "        \n",
        "        if K.backend() == \"tensorflow\": \n",
        "            gradients = self.get_gradients[outc](_input)\n",
        "        elif K.backend() == \"theano\":\n",
        "            gradients = self.get_gradients[outc](_input)\n",
        "            if len(self.model.inputs) == 1:\n",
        "                gradients = [gradients]\n",
        "        \n",
        "        explanation = []\n",
        "        for i in range(len(gradients)):\n",
        "            _temp = np.sum(gradients[i], axis=0)\n",
        "            explanation.append(np.multiply(_temp, step_sizes[i]))\n",
        "           \n",
        "        # Format the return values according to the input sample.\n",
        "        if isinstance(sample, list):\n",
        "            return explanation\n",
        "        elif isinstance(sample, np.ndarray):\n",
        "            return explanation[0]\n",
        "        return -1\n",
        "\n",
        "    \n",
        "    '''\n",
        "    Input: numpy array of a sample\n",
        "    Optional inputs:\n",
        "        - reference: reference values (defaulted to 0s).\n",
        "        - steps: # steps from reference values to the actual sample.\n",
        "    Output: list of numpy arrays to integrate over.\n",
        "    '''\n",
        "    @staticmethod\n",
        "    def linearly_interpolate(sample, reference=False, num_steps=50):\n",
        "        # Use default reference values if reference is not specified\n",
        "        if reference is False: reference = np.zeros(sample.shape);\n",
        "\n",
        "        # Reference and sample shape needs to match exactly\n",
        "        assert sample.shape == reference.shape\n",
        "\n",
        "        # Calcuated stepwise difference from reference to the actual sample.\n",
        "        ret = np.zeros(tuple([num_steps] +[i for i in sample.shape]))\n",
        "        for s in range(num_steps):\n",
        "            ret[s] = reference+(sample-reference)*(s*1.0/num_steps)\n",
        "\n",
        "        return ret, num_steps, (sample-reference)*(1.0/num_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jSWlj3lVqiF2",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16 as ModelTypeObj\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z51s3UvUqiF5",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PsjkJ4AHqiF7",
        "colab": {}
      },
      "source": [
        "cd '/gdrive/My Drive/MVTEC_LEATHER/EXP/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X8WgIvDFqiF8"
      },
      "source": [
        "### NG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VR3eqjxtqiF9"
      },
      "source": [
        "#### Step 1. Load the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNHpvHhAqiF-",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model('my_mvtec_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5zsznpZgqiF_"
      },
      "source": [
        "#### Step 2. Be sure to complie it and add an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hY96wpaIqiF_",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N68KkDWmqiGC"
      },
      "source": [
        "#### Step 3. Wrap it with integrated gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9-kPPZ8NqiGC",
        "colab": {}
      },
      "source": [
        "ig = integrated_gradients(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "koVT1qf0qiGE"
      },
      "source": [
        "#### Step 4. Obtain a sample to explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qvs6Dt1mqiGE",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "# load an image\n",
        "file = random.choice(glob.glob('/gdrive/My Drive/MVTEC_LEATHER/EXP/Test/NG/*.jpg'))\n",
        "\n",
        "img = image.load_img(file, target_size=(224, 224))\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(img)\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mNGKr9I5qiGF",
        "colab": {}
      },
      "source": [
        "# preprocess image\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x/255.0\n",
        "\n",
        "# preprocess reference as well\n",
        "ref = np.zeros((224, 224, 3))\n",
        "ref = np.expand_dims(ref, axis=0)\n",
        "#ref = preprocess_input(ref)\n",
        "ref = ref/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oQCODwGLqiGH"
      },
      "source": [
        "#### Step 5. Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DrxM3vqVqiGH",
        "colab": {}
      },
      "source": [
        "labels = ['NG','OK']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XAws5B-qiGI",
        "colab": {}
      },
      "source": [
        "pred = model.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eVARPGa_qiGJ",
        "colab": {}
      },
      "source": [
        "predicted = np.argmax(pred)\n",
        "print (\"Predicted label:\", labels[predicted])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8VJR2I5SqiGK"
      },
      "source": [
        "Step 6. Explain with respect to the true label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kObNH63pqiGK",
        "colab": {}
      },
      "source": [
        "exp = ig.explain(x[0], reference=ref[0], outc=predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KQwN7sxFqiGL",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img)\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.title(\"Original image\")\n",
        "\n",
        "th = max(np.abs(np.min(exp)), np.abs(np.max(exp)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.sum(exp, axis=2), cmap=\"seismic\", vmin=-1*th, vmax=th)\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.title(\"Explanation\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5GRdXbTxqiGM",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OEWiyAApqiGO"
      },
      "source": [
        "OK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rfDMxoBVqiGO"
      },
      "source": [
        "#### Step 1. Load the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cpkeDHegqiGO",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model('my_mvtec_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TmxmyQH0qiGP"
      },
      "source": [
        "#### Step 2. Be sure to complie it and add an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KAtHTuzyqiGP",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dSDseHz5qiGT"
      },
      "source": [
        "#### Step 3. Wrap it with integrated gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gksw07RqqiGU",
        "colab": {}
      },
      "source": [
        "ig = integrated_gradients(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uCZQ1prbqiGV"
      },
      "source": [
        "#### Step 4. Obtain a sample to explain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WFLdd6ltqiGV",
        "colab": {}
      },
      "source": [
        "import glob, random\n",
        "\n",
        "# load an image\n",
        "file = random.choice(glob.glob('/gdrive/My Drive/MVTEC_LEATHER/EXP/Test/OK/*.jpg'))\n",
        "\n",
        "img = image.load_img(file, target_size=(224, 224))\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(img)\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HQpR9nrRqiGW",
        "colab": {}
      },
      "source": [
        "# preprocess image\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x/255.0\n",
        "\n",
        "# preprocess reference as well\n",
        "ref = np.zeros((224, 224, 3))\n",
        "ref = np.expand_dims(ref, axis=0)\n",
        "ref = ref/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iNJI9KJsqiGX"
      },
      "source": [
        "#### Step 5. Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwr1lXiSqiGX",
        "colab": {}
      },
      "source": [
        "labels = ['NG','OK']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "irncmWjCqiGY",
        "colab": {}
      },
      "source": [
        "pred = model.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8IVaJ_clqiGZ",
        "colab": {}
      },
      "source": [
        "predicted = np.argmax(pred)\n",
        "print (\"Predicted label:\", labels[predicted])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "29L8lYISqiGa"
      },
      "source": [
        "Step 6. Explain with respect to the true label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ceQgeVIcqiGa",
        "colab": {}
      },
      "source": [
        "exp = ig.explain(x[0], reference=ref[0], outc=predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1HUgWDMFqiGb",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(4,2))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img)\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.title(\"Original image\")\n",
        "\n",
        "th = max(np.abs(np.min(exp)), np.abs(np.max(exp)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.sum(exp, axis=2), cmap=\"seismic\", vmin=-1*th, vmax=th)\n",
        "plt.xticks([], [])\n",
        "plt.yticks([], [])\n",
        "plt.title(\"Explanation\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O9fmqNvPqiGc",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQoH2v1fZ-dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ4DXWsuqn0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSJUhiPWaiAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd '/gdrive/My Drive/MVTEC_LEATHER/EXP/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYw7bvbQ3TZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}